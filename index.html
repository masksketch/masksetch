<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <title>MaskSketch: Unpaired Structure-guided Masked Image Generation </title>
    <link media="all" href="css.css" type="text/css" rel="StyleSheet">

  </head>
  <body>
<body>
<div id="primarycontent">
<center><h1><b>MaskSketch</b>: </br> Unpaired Structure-guided Masked Image Generation</h1></center>
<center><h2>
	<a href="https://cs-people.bu.edu/dbash/">Dina Bashkirova</a>&nbsp;&nbsp;&nbsp;
	<a href="http://iie.fing.edu.uy/~jlezama/">Jose Lezama</a>&nbsp;&nbsp;&nbsp;
	<a href="https://sites.google.com/site/kihyuksml/?pli=1">Kihyuk Sohn</a>&nbsp;&nbsp;&nbsp;
	<a href="http://ai.bu.edu/ksaenko.html">Kate Saenko</a>&nbsp;&nbsp;&nbsp;
	<a href="https://www.cc.gatech.edu/people/irfan-essa">Irfan Essa</a>
	</h2>

	<center><h2>
		Boston University&nbsp;&nbsp;&nbsp;
		Google Research&nbsp;&nbsp;&nbsp;
		Georgia Tech University &nbsp;&nbsp;&nbsp;

		</h2></center>
<!-- 	<center><h2>under review</h2></center> -->
<center><h2><strong><a href="paper.pdf">Paper</a> <a href="https://github.com/google-research/masksketch"> Code </a></strong> </h2></center>

</br>
<!-- <div style="font-size:14px"><p align="justify"> 
<div class="row">
  <div style="float: left; width: 50%">
    <img src="wpage_fig_1.png" alt="fig_1" height="500">
  </div>
  <div style="float: left; width: 50%">
    <img src="wpage_fig_2.png" alt="fig_2" height="500">
  </div>

</div> -->
	
<center style="margin-top:1cm;">
    <img src="wpage_fig_1.png" width="500">
    </br>
    </br>
    <img src="wpage_fig_2.png" width="500">
</center>

<div class="row" style="font-size:14px"><p align="justify">	
Given an input sketch and its class label, MaskSketch samples realistic images that follow the given structure. MaskSketech works on sketches of various degrees of abstraction by leveraging a pre-trained masked image generator, while not requiring model finetuning or pairwise supervision. 	
</p></div>


</br>
<h2 align="center">Abstract</h2>
</br>
<div style="font-size:14px"><p align="justify"> Recent conditional image generation methods produce images of
   remarkable diversity, fidelity and realism. However, the majority
   of these methods allow conditioning only on labels or text prompts,
   which limits their level of control over the generation result. In
   this paper, we introduce MaskSketch, an image generation
   method that allows spatial conditioning of the generation result
   using a guiding sketch as an extra conditioning signal during sampling. MaskSketch
   utilizes a pre-trained masked generative transformer, requiring no model
   training or paired supervision, and works with input sketches of
   different levels of abstraction. 
   We show that intermediate self-attention maps of a masked generative transformer encode important structural information of the input image, such as scene layout and object shape, and we propose a novel sampling method based on this observation to enable structure-guided generation.  Our results show that
   MaskSketch achieves high image realism and fidelity to the guiding
   structure. Evaluated on standard benchmark datasets, MaskSketch
   outperforms state-of-the-art methods for sketch-to-image
   translation, as well as unpaired image-to-image translation
   approaches.
	
	</p></div>

</br>
</br>
</br>
<h2 align="center">Citation</h2>
<pre align="left"><code align="left">
@inproceedings{bashkirova@masksketch,
    author    = {Bashkirova, Dina and Lezama, Jose and Sohn, Kihyuk and Saenko, Kate and Essa, Irfan },
    title     = {},
    booktitle = {},
    month     = {November},
    year      = {2022}
}
</pre></code>
</br></br></br></br>
</body>
